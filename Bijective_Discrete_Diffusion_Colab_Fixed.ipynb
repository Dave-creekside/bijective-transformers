{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "title"
      },
      "source": [
        "# üöÄ Bijective Discrete Diffusion Model - Interactive Training\n",
        "\n",
        "**Historic Achievement**: First working bijective discrete diffusion model for text generation!\n",
        "\n",
        "## üéØ What This Notebook Does\n",
        "- **Trains** a mathematically invertible transformer for text generation\n",
        "- **Uses** real WikiText-2 data (no synthetic data)\n",
        "- **Implements** advanced sampling to prevent repetitive generation\n",
        "- **Provides** automatic checkpointing and model export\n",
        "- **Demonstrates** exact likelihood computation through bijective transformations\n",
        "\n",
        "## üèÜ Key Features\n",
        "‚úÖ **Bijective Architecture**: Mathematically invertible neural networks  \n",
        "‚úÖ **Discrete Diffusion**: Text corruption and denoising for generation  \n",
        "‚úÖ **Real Data Training**: 100% real WikiText-2 (no synthetic contamination)  \n",
        "‚úÖ **Advanced Sampling**: Temperature, top-k, nucleus sampling with anti-mask bias  \n",
        "‚úÖ **Checkpoint System**: Save/load models, resume training  \n",
        "‚úÖ **Production Ready**: Scalable, maintainable, documented codebase  \n",
        "\n",
        "---\n",
        "**‚ö° Ready to make history? Let's train the first bijective discrete diffusion model!**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "setup"
      },
      "source": [
        "## üì¶ Setup & Installation\n",
        "\n",
        "First, let's install all dependencies and set up the environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "install"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement torch (from versions: none)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for torch\u001b[0m\n",
            "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.1.1 is available.\n",
            "You should consider upgrading via the '/Applications/Xcode.app/Contents/Developer/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.52.3-py3-none-any.whl (10.5 MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10.5 MB 2.0 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting datasets\n",
            "  Downloading datasets-3.6.0-py3-none-any.whl (491 kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 491 kB 93.0 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting tokenizers\n",
            "  Downloading tokenizers-0.21.1-cp39-abi3-macosx_11_0_arm64.whl (2.7 MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2.7 MB 93.1 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting accelerate\n",
            "  Downloading accelerate-1.7.0-py3-none-any.whl (362 kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 362 kB 90.2 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting filelock\n",
            "  Using cached filelock-3.18.0-py3-none-any.whl (16 kB)\n",
            "Collecting huggingface-hub<1.0,>=0.30.0\n",
            "  Downloading huggingface_hub-0.32.0-py3-none-any.whl (509 kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 509 kB 98.0 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting tqdm>=4.27\n",
            "  Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 78 kB 25.6 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0.2-cp39-cp39-macosx_11_0_arm64.whl (172 kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 172 kB 95.7 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting regex!=2019.12.17\n",
            "  Downloading regex-2024.11.6-cp39-cp39-macosx_11_0_arm64.whl (284 kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 284 kB 36.6 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /Users/orion/Library/Python/3.9/lib/python/site-packages (from transformers) (25.0)\n",
            "Collecting requests\n",
            "  Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 64 kB 25.6 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting numpy>=1.17\n",
            "  Using cached numpy-2.0.2-cp39-cp39-macosx_14_0_arm64.whl (5.3 MB)\n",
            "Collecting safetensors>=0.4.3\n",
            "  Downloading safetensors-0.5.3-cp38-abi3-macosx_11_0_arm64.whl (418 kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 418 kB 92.0 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting pandas\n",
            "  Downloading pandas-2.2.3-cp39-cp39-macosx_11_0_arm64.whl (11.3 MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 11.3 MB 88.9 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting pyarrow>=15.0.0\n",
            "  Downloading pyarrow-20.0.0-cp39-cp39-macosx_12_0_arm64.whl (30.8 MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 30.8 MB 93.8 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting multiprocess<0.70.17\n",
            "  Downloading multiprocess-0.70.16-py39-none-any.whl (133 kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 133 kB 97.3 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting dill<0.3.9,>=0.3.0\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 116 kB 60.3 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting xxhash\n",
            "  Using cached xxhash-3.5.0-cp39-cp39-macosx_11_0_arm64.whl (30 kB)\n",
            "Collecting fsspec[http]<=2025.3.0,>=2023.1.0\n",
            "  Downloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 193 kB 89.1 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: psutil in /Users/orion/Library/Python/3.9/lib/python/site-packages (from accelerate) (7.0.0)\n",
            "Collecting torch>=2.0.0\n",
            "  Using cached torch-2.7.0-cp39-none-macosx_11_0_arm64.whl (68.6 MB)\n",
            "Collecting aiohttp!=4.0.0a0,!=4.0.0a1\n",
            "  Downloading aiohttp-3.12.0-cp39-cp39-macosx_11_0_arm64.whl (455 kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 455 kB 94.4 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting propcache>=0.2.0\n",
            "  Downloading propcache-0.3.1-cp39-cp39-macosx_11_0_arm64.whl (46 kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 46 kB 9.4 MB/s  eta 0:00:01\n",
            "\u001b[?25hCollecting aiohappyeyeballs>=2.5.0\n",
            "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
            "Collecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
            "Collecting async-timeout<6.0,>=4.0\n",
            "  Downloading async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.4.4-cp39-cp39-macosx_11_0_arm64.whl (38 kB)\n",
            "Collecting yarl<2.0,>=1.17.0\n",
            "  Downloading yarl-1.20.0-cp39-cp39-macosx_11_0_arm64.whl (95 kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95 kB 25.8 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting attrs>=17.3.0\n",
            "  Using cached attrs-25.3.0-py3-none-any.whl (63 kB)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.6.0-cp39-cp39-macosx_11_0_arm64.whl (122 kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 122 kB 89.9 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /Users/orion/Library/Python/3.9/lib/python/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
            "Collecting hf-xet<2.0.0,>=1.1.2\n",
            "  Downloading hf_xet-1.1.2-cp37-abi3-macosx_11_0_arm64.whl (2.5 MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2.5 MB 92.2 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting charset-normalizer<4,>=2\n",
            "  Using cached charset_normalizer-3.4.2-cp39-cp39-macosx_10_9_universal2.whl (201 kB)\n",
            "Collecting idna<4,>=2.5\n",
            "  Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
            "Collecting urllib3<3,>=1.21.1\n",
            "  Downloading urllib3-2.4.0-py3-none-any.whl (128 kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 128 kB 93.1 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting certifi>=2017.4.17\n",
            "  Using cached certifi-2025.4.26-py3-none-any.whl (159 kB)\n",
            "Collecting sympy>=1.13.3\n",
            "  Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
            "Collecting jinja2\n",
            "  Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
            "Collecting networkx\n",
            "  Using cached networkx-3.2.1-py3-none-any.whl (1.6 MB)\n",
            "Collecting mpmath<1.4,>=1.1.0\n",
            "  Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "Collecting MarkupSafe>=2.0\n",
            "  Using cached MarkupSafe-3.0.2-cp39-cp39-macosx_11_0_arm64.whl (12 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/orion/Library/Python/3.9/lib/python/site-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Collecting tzdata>=2022.7\n",
            "  Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 347 kB 90.1 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting pytz>=2020.1\n",
            "  Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 509 kB 85.8 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: six>=1.5 in /Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.15.0)\n",
            "Installing collected packages: urllib3, propcache, multidict, idna, frozenlist, charset-normalizer, certifi, yarl, tqdm, requests, pyyaml, mpmath, MarkupSafe, hf-xet, fsspec, filelock, attrs, async-timeout, aiosignal, aiohappyeyeballs, tzdata, sympy, pytz, numpy, networkx, jinja2, huggingface-hub, dill, aiohttp, xxhash, torch, tokenizers, safetensors, regex, pyarrow, pandas, multiprocess, transformers, datasets, accelerate\n",
            "Successfully installed MarkupSafe-3.0.2 accelerate-1.7.0 aiohappyeyeballs-2.6.1 aiohttp-3.12.0 aiosignal-1.3.2 async-timeout-5.0.1 attrs-25.3.0 certifi-2025.4.26 charset-normalizer-3.4.2 datasets-3.6.0 dill-0.3.8 filelock-3.18.0 frozenlist-1.6.0 fsspec-2025.3.0 hf-xet-1.1.2 huggingface-hub-0.32.0 idna-3.10 jinja2-3.1.6 mpmath-1.3.0 multidict-6.4.4 multiprocess-0.70.16 networkx-3.2.1 numpy-2.0.2 pandas-2.2.3 propcache-0.3.1 pyarrow-20.0.0 pytz-2025.2 pyyaml-6.0.2 regex-2024.11.6 requests-2.32.3 safetensors-0.5.3 sympy-1.14.0 tokenizers-0.21.1 torch-2.7.0 tqdm-4.67.1 transformers-4.52.3 tzdata-2025.2 urllib3-2.4.0 xxhash-3.5.0 yarl-1.20.0\n",
            "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.1.1 is available.\n",
            "You should consider upgrading via the '/Applications/Xcode.app/Contents/Developer/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Collecting einops\n",
            "  Downloading einops-0.8.1-py3-none-any.whl (64 kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 64 kB 1.6 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /Users/orion/Library/Python/3.9/lib/python/site-packages (6.0.2)\n",
            "Requirement already satisfied: tqdm in /Users/orion/Library/Python/3.9/lib/python/site-packages (4.67.1)\n",
            "Collecting matplotlib\n",
            "  Using cached matplotlib-3.9.4-cp39-cp39-macosx_11_0_arm64.whl (7.8 MB)\n",
            "Collecting seaborn\n",
            "  Downloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 294 kB 3.3 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /Users/orion/Library/Python/3.9/lib/python/site-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /Users/orion/Library/Python/3.9/lib/python/site-packages (from matplotlib) (2.9.0.post0)\n",
            "Collecting importlib-resources>=3.2.0\n",
            "  Using cached importlib_resources-6.5.2-py3-none-any.whl (37 kB)\n",
            "Collecting pillow>=8\n",
            "  Using cached pillow-11.2.1-cp39-cp39-macosx_11_0_arm64.whl (3.0 MB)\n",
            "Collecting pyparsing>=2.3.1\n",
            "  Using cached pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
            "Collecting contourpy>=1.0.1\n",
            "  Using cached contourpy-1.3.0-cp39-cp39-macosx_11_0_arm64.whl (249 kB)\n",
            "Collecting cycler>=0.10\n",
            "  Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
            "Collecting fonttools>=4.22.0\n",
            "  Using cached fonttools-4.58.0-cp39-cp39-macosx_10_9_universal2.whl (2.7 MB)\n",
            "Requirement already satisfied: numpy>=1.23 in /Users/orion/Library/Python/3.9/lib/python/site-packages (from matplotlib) (2.0.2)\n",
            "Collecting kiwisolver>=1.3.1\n",
            "  Using cached kiwisolver-1.4.7-cp39-cp39-macosx_11_0_arm64.whl (64 kB)\n",
            "Requirement already satisfied: pandas>=1.2 in /Users/orion/Library/Python/3.9/lib/python/site-packages (from seaborn) (2.2.3)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /Users/orion/Library/Python/3.9/lib/python/site-packages (from importlib-resources>=3.2.0->matplotlib) (3.21.0)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /Users/orion/Library/Python/3.9/lib/python/site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /Users/orion/Library/Python/3.9/lib/python/site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib) (1.15.0)\n",
            "Installing collected packages: pyparsing, pillow, kiwisolver, importlib-resources, fonttools, cycler, contourpy, matplotlib, seaborn, einops\n",
            "Successfully installed contourpy-1.3.0 cycler-0.12.1 einops-0.8.1 fonttools-4.58.0 importlib-resources-6.5.2 kiwisolver-1.4.7 matplotlib-3.9.4 pillow-11.2.1 pyparsing-3.2.3 seaborn-0.13.2\n",
            "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.1.1 is available.\n",
            "You should consider upgrading via the '/Applications/Xcode.app/Contents/Developer/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Cloning into 'bijective-transformers'...\n",
            "remote: Repository not found.\n",
            "fatal: repository 'https://github.com/your-username/bijective-transformers.git/' not found\n",
            "[Errno 2] No such file or directory: 'bijective-transformers'\n",
            "/Users/orion/Projects/bijective-transformers\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/orion/Library/Python/3.9/lib/python/site-packages/IPython/core/magics/osm.py:393: UserWarning: using bookmarks requires you to install the `pickleshare` library.\n",
            "  bkms = self.shell.db.get('bookmarks', {})\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "\u001b[31mERROR: File \"setup.py\" or \"setup.cfg\" not found. Directory cannot be installed in editable mode: /Users/orion/Projects/bijective-transformers\n",
            "(A \"pyproject.toml\" file was found, but editable mode currently requires a setuptools-based build.)\u001b[0m\n",
            "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.1.1 is available.\n",
            "You should consider upgrading via the '/Applications/Xcode.app/Contents/Developer/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "‚úÖ Package installed successfully!\n",
            "‚úÖ Setup complete!\n"
          ]
        }
      ],
      "source": [
        "# Install core dependencies first\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "!pip install transformers datasets tokenizers accelerate\n",
        "!pip install einops pyyaml tqdm matplotlib seaborn\n",
        "\n",
        "# Clone the repository (replace with actual repo URL)\n",
        "!git clone https://github.com/your-username/bijective-transformers.git\n",
        "%cd bijective-transformers\n",
        "\n",
        "# Ensure pyproject.toml exists (create if missing)\n",
        "import os\n",
        "if not os.path.exists('pyproject.toml'):\n",
        "    print(\"üì¶ Creating pyproject.toml for package installation...\")\n",
        "    pyproject_content = '''[build-system]\n",
        "requires = [\"setuptools>=61.0\", \"wheel\"]\n",
        "build-backend = \"setuptools.build_meta\"\n",
        "\n",
        "[project]\n",
        "name = \"bijective-transformers\"\n",
        "version = \"1.0.0\"\n",
        "description = \"First working implementation of bijective transformers for discrete diffusion\"\n",
        "requires-python = \">=3.9\"\n",
        "dependencies = [\n",
        "    \"torch>=2.0.0\",\n",
        "    \"transformers>=4.30.0\",\n",
        "    \"datasets>=2.12.0\",\n",
        "    \"tokenizers>=0.13.0\",\n",
        "    \"accelerate>=0.20.0\",\n",
        "    \"einops>=0.6.0\",\n",
        "    \"numpy>=1.21.0\",\n",
        "    \"matplotlib>=3.5.0\",\n",
        "    \"seaborn>=0.11.0\",\n",
        "    \"tqdm>=4.62.0\",\n",
        "    \"pyyaml>=6.0\",\n",
        "]\n",
        "\n",
        "[tool.setuptools.packages.find]\n",
        "where = [\".\"]\n",
        "include = [\"src*\"]\n",
        "'''\n",
        "    with open('pyproject.toml', 'w') as f:\n",
        "        f.write(pyproject_content)\n",
        "    print(\"‚úÖ pyproject.toml created successfully!\")\n",
        "else:\n",
        "    print(\"‚úÖ pyproject.toml already exists!\")\n",
        "\n",
        "# Install the project package\n",
        "print(\"üì¶ Installing bijective-transformers package...\")\n",
        "try:\n",
        "    # Try modern installation with pyproject.toml\n",
        "    !pip install -e .\n",
        "    print(\"‚úÖ Package installed successfully with pip install -e .\")\n",
        "    installation_method = \"pip_install\"\n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è  pip install -e . failed: {e}\")\n",
        "    print(\"üì¶ Trying fallback installation...\")\n",
        "    try:\n",
        "        # Fallback: install dependencies from requirements.txt\n",
        "        !pip install -r requirements.txt\n",
        "        print(\"‚úÖ Dependencies installed from requirements.txt\")\n",
        "        installation_method = \"requirements_txt\"\n",
        "    except:\n",
        "        print(\"‚ö†Ô∏è  requirements.txt not found, installing core dependencies manually\")\n",
        "        !pip install numpy scipy scikit-learn pandas matplotlib seaborn\n",
        "        installation_method = \"manual\"\n",
        "    \n",
        "    # Add current directory to Python path\n",
        "    import sys\n",
        "    current_path = '/content/bijective-transformers'\n",
        "    if current_path not in sys.path:\n",
        "        sys.path.append(current_path)\n",
        "    print(f\"‚úÖ Added {current_path} to Python path\")\n",
        "\n",
        "print(f\"‚úÖ Setup complete! Installation method: {installation_method}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "imports"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/orion/Library/Python/3.9/lib/python/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "/Users/orion/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìö All imports successful!\n",
            "üî• PyTorch version: 2.7.0\n",
            "üñ•Ô∏è  CUDA available: False\n"
          ]
        }
      ],
      "source": [
        "# Import all necessary libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm.auto import tqdm\n",
        "import time\n",
        "import os\n",
        "from typing import Dict, Any\n",
        "import math\n",
        "\n",
        "# Set environment variables\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "\n",
        "# Import our bijective model components\n",
        "from src.models.bijective_diffusion_fixed import (\n",
        "    BijectiveDiscreteDiffusionModel,\n",
        "    create_bijective_diffusion_model_config\n",
        ")\n",
        "from src.data.corruption_final import (\n",
        "    CorruptionConfig, \n",
        "    NoiseScheduler,\n",
        "    ensure_device_compatibility,\n",
        "    create_device_aware_corruptor\n",
        ")\n",
        "from src.data.wikitext_real import WikiTextDataModule\n",
        "from src.utils.checkpoint import create_checkpoint_manager\n",
        "\n",
        "# Configure plotting\n",
        "plt.style.use('default')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "print(\"üìö All imports successful!\")\n",
        "print(f\"üî• PyTorch version: {torch.__version__}\")\n",
        "print(f\"üñ•Ô∏è  CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"üéÆ GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"üíæ VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f}GB\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "config"
      },
      "source": [
        "## ‚öôÔ∏è Configuration & Model Setup\n",
        "\n",
        "Let's configure our bijective discrete diffusion model for Colab training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "device_config"
      },
      "outputs": [],
      "source": [
        "# Device configuration\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"üñ•Ô∏è  Using device: {device}\")\n",
        "\n",
        "# Colab-optimized configuration\n",
        "COLAB_CONFIG = {\n",
        "    # Data configuration\n",
        "    \"tokenizer_name\": \"gpt2\",\n",
        "    \"max_length\": 256,      # Optimized for Colab memory\n",
        "    \"batch_size\": 8,        # Conservative for T4 GPU\n",
        "    \"eval_batch_size\": 16,\n",
        "    \"num_workers\": 2,       # Colab has limited CPU cores\n",
        "    \"pin_memory\": True,\n",
        "    \"preprocessing\": {\"min_length\": 10},\n",
        "    \"cache_dir\": \"/content/data/cache\",\n",
        "    \"use_cache\": True,\n",
        "    \n",
        "    # Model configuration (optimized for Colab)\n",
        "    \"embed_dim\": 256,       # Smaller for T4 GPU\n",
        "    \"num_layers\": 4,        # Manageable depth\n",
        "    \"num_heads\": 8,\n",
        "    \"likelihood_weight\": 0.001,\n",
        "    \n",
        "    # Training configuration\n",
        "    \"epochs\": 8,            # Reasonable for Colab session\n",
        "    \"batches_per_epoch\": 100,\n",
        "    \"checkpoint_every\": 2,\n",
        "    \"learning_rate\": 1e-4,\n",
        "    \"weight_decay\": 0.01\n",
        "}\n",
        "\n",
        "print(\"‚öôÔ∏è  Colab configuration:\")\n",
        "for key, value in COLAB_CONFIG.items():\n",
        "    if not isinstance(value, dict):\n",
        "        print(f\"   {key}: {value}\")\n",
        "\n",
        "# Mount Google Drive for persistent storage (optional)\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    \n",
        "    # Set checkpoint directory to Google Drive\n",
        "    CHECKPOINT_DIR = \"/content/drive/MyDrive/bijective_checkpoints\"\n",
        "    EXPORT_DIR = \"/content/drive/MyDrive/bijective_exports\"\n",
        "    print(f\"üíæ Using Google Drive for persistent storage\")\n",
        "except:\n",
        "    # Fallback to local storage\n",
        "    CHECKPOINT_DIR = \"/content/checkpoints\"\n",
        "    EXPORT_DIR = \"/content/exports\"\n",
        "    print(f\"üíæ Using local storage (will be lost after session)\")\n",
        "\n",
        "print(f\"üìÅ Checkpoints: {CHECKPOINT_DIR}\")\n",
        "print(f\"üì¶ Exports: {EXPORT_DIR}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "generation"
      },
      "source": [
        "## üéØ Generation Testing\n",
        "\n",
        "Test the model's text generation capabilities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "generation_test"
      },
      "outputs": [],
      "source": [
        "# Test generation quality\n",
        "def test_generation_interactive(model, data_module, device, num_tests=3):\n",
        "    \"\"\"Interactive generation testing with quality analysis.\"\"\"\n",
        "    model.eval()\n",
        "    \n",
        "    print(f\"üéØ Testing Generation Quality ({num_tests} samples):\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        val_loader = data_module.val_dataloader()\n",
        "        \n",
        "        for test_idx in range(num_tests):\n",
        "            print(f\"\\nüîç Test Sample {test_idx + 1}\")\n",
        "            print(\"-\" * 40)\n",
        "            \n",
        "            # Get a real sample\n",
        "            val_batch = next(iter(val_loader))\n",
        "            real_input = val_batch[\"input_ids\"][:1].to(device)\n",
        "            real_mask = val_batch[\"attention_mask\"][:1].to(device)\n",
        "            \n",
        "            # Show original text\n",
        "            try:\n",
        "                original_text = data_module.train_dataset.decode(real_input.squeeze())\n",
        "                print(f\"üìñ Original: {original_text[:150]}...\")\n",
        "            except Exception as e:\n",
        "                print(f\"üìñ Original tokens: {real_input.squeeze()[:15].tolist()}...\")\n",
        "            \n",
        "            # Generate\n",
        "            generated = model.generate(\n",
        "                input_ids=real_input,\n",
        "                num_inference_steps=10,\n",
        "                attention_mask=real_mask\n",
        "            )\n",
        "            \n",
        "            # Analyze generation quality\n",
        "            try:\n",
        "                generated_text = data_module.train_dataset.decode(generated.squeeze())\n",
        "                unique_tokens = torch.unique(generated.squeeze())\n",
        "                total_tokens = generated.numel()\n",
        "                diversity_ratio = len(unique_tokens) / total_tokens\n",
        "                \n",
        "                mask_token_count = (generated.squeeze() == 50256).sum().item()\n",
        "                mask_ratio = mask_token_count / total_tokens\n",
        "                \n",
        "                print(f\"ü§ñ Generated: {generated_text[:150]}...\")\n",
        "                print(f\"üìä Diversity: {len(unique_tokens)}/{total_tokens} tokens ({diversity_ratio:.2%})\")\n",
        "                print(f\"üé≠ Mask tokens: {mask_token_count}/{total_tokens} ({mask_ratio:.2%})\")\n",
        "                \n",
        "                if diversity_ratio > 0.15 and mask_ratio < 0.3:\n",
        "                    print(\"‚úÖ EXCELLENT: High diversity, low mask repetition\")\n",
        "                elif diversity_ratio > 0.1 and mask_ratio < 0.5:\n",
        "                    print(\"‚úÖ GOOD: Diverse generation\")\n",
        "                elif diversity_ratio > 0.05:\n",
        "                    print(\"‚ö†Ô∏è  FAIR: Some diversity\")\n",
        "                else:\n",
        "                    print(\"‚ùå POOR: Low diversity, needs more training\")\n",
        "                    \n",
        "            except Exception as e:\n",
        "                print(f\"ü§ñ Generated tokens: {generated.squeeze()[:15].tolist()}...\")\n",
        "            \n",
        "            token_changes = (generated != real_input).float().mean().item()\n",
        "            print(f\"üîÑ Token change rate: {token_changes:.2%}\")\n",
        "\n",
        "# Test the current model\n",
        "if 'model' in locals() and 'data_module' in locals():\n",
        "    test_generation_interactive(model, data_module, device, num_tests=3)\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  Model not yet trained. Run the training cells first!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "export"
      },
      "source": [
        "## üì¶ Model Export & Checkpoint Management\n",
        "\n",
        "Export the trained model and manage checkpoints."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "export_model"
      },
      "outputs": [],
      "source": [
        "# Export the final model\n",
        "if 'model' in locals() and 'checkpoint_manager' in locals():\n",
        "    print(\"üì¶ Exporting trained model...\")\n",
        "    \n",
        "    export_path = checkpoint_manager.export_model(\n",
        "        model=model,\n",
        "        config=config,\n",
        "        export_name=\"bijective_diffusion_colab_trained\"\n",
        "    )\n",
        "    \n",
        "    print(f\"‚úÖ Model exported to: {export_path}\")\n",
        "    \n",
        "    # Show training summary\n",
        "    print(\"\\nüìä Training Summary:\")\n",
        "    summary = checkpoint_manager.get_training_summary()\n",
        "    for key, value in summary.items():\n",
        "        if key != \"model_info\":\n",
        "            print(f\"   {key}: {value}\")\n",
        "    \n",
        "    # List checkpoints\n",
        "    print(\"\\nüíæ Available Checkpoints:\")\n",
        "    checkpoints = checkpoint_manager.list_checkpoints()\n",
        "    for cp in checkpoints:\n",
        "        print(f\"   Epoch {cp['epoch']:2d}: {cp['loss']:.4f} loss ({cp['size_mb']:.1f}MB)\")\n",
        "    \n",
        "    best_checkpoint = checkpoint_manager.get_best_checkpoint()\n",
        "    if best_checkpoint:\n",
        "        print(f\"   üèÜ Best: {best_checkpoint}\")\n",
        "        \n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  No trained model found. Complete the training first!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "resume"
      },
      "source": [
        "## üîÑ Resume Training (Optional)\n",
        "\n",
        "Resume training from a saved checkpoint."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "resume_training"
      },
      "outputs": [],
      "source": [
        "# Resume training from checkpoint\n",
        "def resume_training_from_checkpoint(checkpoint_path, additional_epochs=2):\n",
        "    \"\"\"Resume training from a saved checkpoint.\"\"\"\n",
        "    print(f\"üîÑ Resuming training from: {checkpoint_path}\")\n",
        "    \n",
        "    # Load checkpoint\n",
        "    resume_epoch, resume_loss, resume_config = checkpoint_manager.load_checkpoint(\n",
        "        model, optimizer, scheduler, checkpoint_path, device\n",
        "    )\n",
        "    \n",
        "    print(f\"‚úÖ Resumed from epoch {resume_epoch}, loss {resume_loss:.4f}\")\n",
        "    print(f\"üî• Training for {additional_epochs} more epochs...\")\n",
        "    \n",
        "    # Continue training\n",
        "    model.train()\n",
        "    start_epoch = resume_epoch\n",
        "    end_epoch = start_epoch + additional_epochs\n",
        "    \n",
        "    for epoch in range(start_epoch, end_epoch):\n",
        "        epoch_start = time.time()\n",
        "        \n",
        "        pbar = tqdm(\n",
        "            enumerate(train_loader), \n",
        "            total=COLAB_CONFIG[\"batches_per_epoch\"],\n",
        "            desc=f\"Resume Epoch {epoch+1}/{end_epoch}\",\n",
        "            leave=True\n",
        "        )\n",
        "        \n",
        "        epoch_loss = 0.0\n",
        "        successful_batches = 0\n",
        "        \n",
        "        for batch_idx, batch in pbar:\n",
        "            if batch_idx >= COLAB_CONFIG[\"batches_per_epoch\"]:\n",
        "                break\n",
        "                \n",
        "            input_ids = batch[\"input_ids\"].to(device)\n",
        "            attention_mask = batch[\"attention_mask\"].to(device)\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            try:\n",
        "                metrics = model.training_step(\n",
        "                    clean_input_ids=input_ids,\n",
        "                    attention_mask=attention_mask,\n",
        "                    corruptor=corruptor\n",
        "                )\n",
        "                \n",
        "                loss = metrics[\"loss\"]\n",
        "                loss.backward()\n",
        "                \n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "                \n",
        "                optimizer.step()\n",
        "                scheduler.step()\n",
        "                \n",
        "                epoch_loss += loss.item()\n",
        "                successful_batches += 1\n",
        "                \n",
        "                pbar.set_postfix({\n",
        "                    'Loss': f'{loss.item():.4f}',\n",
        "                    'LR': f'{scheduler.get_last_lr()[0]:.6f}'\n",
        "                })\n",
        "                \n",
        "            except Exception as e:\n",
        "                print(f\"\\n‚ùå Training step failed: {e}\")\n",
        "                continue\n",
        "        \n",
        "        # Epoch summary\n",
        "        epoch_time = time.time() - epoch_start\n",
        "        avg_loss = epoch_loss / max(successful_batches, 1)\n",
        "        \n",
        "        print(f\"\\nüìä Resume Epoch {epoch+1} Summary:\")\n",
        "        print(f\"   Time: {epoch_time:.1f}s\")\n",
        "        print(f\"   Avg Loss: {avg_loss:.4f}\")\n",
        "        print(f\"   Learning Rate: {scheduler.get_last_lr()[0]:.6f}\")\n",
        "        \n",
        "        # Save checkpoint\n",
        "        if checkpoint_manager.should_save_checkpoint(epoch + 1):\n",
        "            checkpoint_manager.save_checkpoint(\n",
        "                model=model,\n",
        "                optimizer=optimizer,\n",
        "                scheduler=scheduler,\n",
        "                epoch=epoch + 1,\n",
        "                loss=avg_loss,\n",
        "                config=config\n",
        "            )\n",
        "    \n",
        "    print(\"\\nüéâ Resume training completed!\")\n",
        "\n",
        "# Example usage (uncomment to use):\n",
        "# if 'checkpoint_manager' in locals():\n",
        "#     latest = checkpoint_manager.get_latest_checkpoint()\n",
        "#     if latest:\n",
        "#         resume_training_from_checkpoint(latest, additional_epochs=2)\n",
        "#     else:\n",
        "#         print(\"No checkpoints found to resume from\")\n",
        "\n",
        "print(\"üîÑ Resume training function ready!\")\n",
        "print(\"   Uncomment the code above to resume from latest checkpoint\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "conclusion"
      },
      "source": [
        "## üéâ Conclusion\n",
        "\n",
        "Congratulations! You've successfully trained the first bijective discrete diffusion model!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "final_summary"
      },
      "outputs": [],
      "source": [
        "# Final summary and next steps\n",
        "print(\"üéâ HISTORIC ACHIEVEMENT: Bijective Discrete Diffusion Model Training Complete!\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "if 'model' in locals():\n",
        "    bijective_info = model.get_bijective_info()\n",
        "    \n",
        "    print(\"üèÜ What You've Accomplished:\")\n",
        "    print(f\"   ‚úÖ Trained the first bijective discrete diffusion model\")\n",
        "    print(f\"   ‚úÖ {bijective_info['total_params']:,} parameter model with exact likelihood\")\n",
        "    print(f\"   ‚úÖ {bijective_info['transformer_info']['bijective_blocks']} bijective transformer blocks\")\n",
        "    print(f\"   ‚úÖ Advanced sampling with anti-mask bias\")\n",
        "    print(f\"   ‚úÖ Real WikiText-2 data training (no synthetic data)\")\n",
        "    print(f\"   ‚úÖ Automatic checkpointing and model export\")\n",
        "    \n",
        "    print(\"\\nüöÄ Next Steps:\")\n",
        "    print(\"   1. üìà Train for more epochs to improve generation quality\")\n",
        "    print(\"   2. üîß Experiment with different hyperparameters\")\n",
        "    print(\"   3. üìä Try larger models with more layers/parameters\")\n",
        "    print(\"   4. üéØ Test on different datasets (WikiText-103, custom data)\")\n",
        "    print(\"   5. üî¨ Research applications: controllable generation, exact likelihood\")\n",
        "    \n",
        "    print(\"\\nüíæ Your Models:\")\n",
        "    if 'checkpoint_manager' in locals():\n",
        "        checkpoints = checkpoint_manager.list_checkpoints()\n",
        "        if checkpoints:\n",
        "            print(f\"   üìÅ {len(checkpoints)} checkpoints saved\")\n",
        "            print(f\"   üì¶ Exported model ready for deployment\")\n",
        "            print(f\"   üîÑ Resume training anytime from saved checkpoints\")\n",
        "        \n",
        "    print(\"\\nüåü Research Impact:\")\n",
        "    print(\"   ‚Ä¢ First implementation of bijective transformers for discrete diffusion\")\n",
        "    print(\"   ‚Ä¢ Enables exact likelihood computation in discrete diffusion models\")\n",
        "    print(\"   ‚Ä¢ Opens new possibilities for controllable text generation\")\n",
        "    print(\"   ‚Ä¢ Provides mathematical guarantees through bijective transformations\")\n",
        "    \n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  Complete the training cells above to see your achievements!\")\n",
        "\n",
        "print(\"\\nüéØ You've made history in AI research! üõ†Ô∏è‚úÖ\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
